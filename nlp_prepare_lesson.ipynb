{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e686dba8",
   "metadata": {},
   "source": [
    "# Parsing Text (aka Prepping Text Data)\n",
    "In this lesson we'll take our acquired data and parse it, that is, we'll better understand the text data by *breaking it down into smaller components.\n",
    "\n",
    "We'll be using the `nltk` package, which requires a little bit of up-front setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6790bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need to install nltk, it should come with anaconda, but nltk needs to download data.\n",
    "# python -c \"import nltk; nltk.download('stopwords')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514d82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from time import strftime\n",
    "\n",
    "import acquire\n",
    "\n",
    "# pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79403204",
   "metadata": {},
   "source": [
    "Here's our plan for parsing the text data:\n",
    "\n",
    "1. Convert text to all lower case for normalcy.\n",
    "1. Remove any accented characters, non-ASCII characters.\n",
    "1. Remove special characters.\n",
    "1. Tokenize the words.\n",
    "1. Stem or lemmatize the words.\n",
    "1. Remove stopwords.\n",
    "1. Store the clean text and the original text for use in future notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d89b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = '''\n",
    "What are the Math and Stats Principles You Need for Data Science?Oct 21, 2020 | Data Science\n",
    "\n",
    "\n",
    "Coming into our Data Science program, you will need to know some math and stats. However, many of our applicants actually learn in the application process – you don’t need to be an expert before applying! Data science is a very accessible field to anyone dedicated to learning new skills, and we can work with any applicant to help them learn what they need to know. But what “skills” do we mean, exactly? Just what exactly are the data science math and stats principles you need to know?\n",
    "What are the main math principles you need to know to get into Codeup’s Data Science program?\n",
    "\n",
    "\n",
    "Algebra\n",
    "Do you know PEMDAS and can you solve for x? You will need to be or become comfortable with the following:\n",
    "\n",
    "Variables (x, y, n, etc.)\n",
    "Formulas, functions, and variable manipulations (e.g. x^2 = x + 6, solve for x).\n",
    "Order of evaluation: PEMDAS: parentheses, exponents, then multiplication, division, addition, and subtraction\n",
    "Commutativity where a + b = b + a\n",
    "Associativity where a + (b + c) = (a + b) + c\n",
    "Adding and subtracting matrices\n",
    "A conceptual understanding of exponential growth/decay- things can increase at an increasing rate\n",
    "\n",
    "Descriptive Statistics\n",
    "Know what a min, max, mode, median, and average are. Have a conceptual understanding that stats/probability is about trying to quantify uncertainty.\n",
    "Data Visualization\n",
    "Know what a scatterplot is and how to read a barplot.\n",
    "How to Learn and Expand on These Concepts\n",
    "There are a number of great resources out there to teach you these and similar concepts. Khan Academy is a great starting place for data science math! If you want to know what exactly we assign our applicants, you’ll just have to apply!\n",
    " \n",
    "What about once you’re in Codeup?\n",
    "\n",
    "\n",
    "What You Won’t Do\n",
    "Do we do any mathematical proofs for concepts or perform derivations? No. \n",
    "Do we do any calculus and probability calculating by hand? No.\n",
    "Are we transforming equations, where we cancel out units or terms and do lots of algebraic gymnastics? No\n",
    "What You Will Do\n",
    "Will we have Python solve our linear algebra problems for us? Yes\n",
    "Will we have Python calculate probabilities, the area under a curve, and the slope of a line for us? Yes\n",
    "Will we have Python do all of the calculus for us? Yes\n",
    " \n",
    "See, the data science math and stats slice of the pie is certainly doable. If you like problem-solving and are ready to challenge yourself, you’ll love data science! If you are interested in learning about data science, just apply! Our Admissions Manager can work with you to get you where you need to be starting from where you are now. Let us help you get there so you can launch a great new career.\n",
    "\n",
    "Request More Info\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Our ProgramsFull Stack Web Development\n",
    "Data Science\n",
    "Cyber Cloud\n",
    "Systems Engineering\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Latest Blog Articles\n",
    "Codeup Dallas Open House\n",
    "Codeup’s Placement Team Continues Setting Records\n",
    "IT Certifications 101: Why They Matter, and Why They Don’t\n",
    "A rise in cyber attacks means opportunities for veterans in San Antonio\n",
    "Use your GI Bill® benefits to Land a Job in Tech\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "More From This Category\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Codeup Dallas Open House\n",
    "Nov 30, 2021 | Dallas Newsletter, EventsCome join us for the re-opening of our Dallas Campus with some drinks and snacks at Codeup! Curious about what our campus looks like? Click here to register for free About this event Come join us for the re-opening of our Dallas Campus with some drinks and snacks at...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Codeup’s Placement Team Continues Setting Records\n",
    "Nov 19, 2021 | Codeup News, EmployersOur Placement Team is simply defined as a group that manages relationships with our employer partners and our graduating students to help get our graduating students hired. Last quarter the Placement Team helped 48 students get hired to life-changing careers in tech....\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "IT Certifications 101: Why They Matter, and Why They Don’t\n",
    "Nov 18, 2021 | Cybersecurity, IT Training, Tips for Prospective StudentsAWS, Google, Azure, Red Hat, CompTIA...these are big names in IT! And not only for their products, but also for the certifications they offer. If you’re new to tech, you might be wondering: Do certifications really matter? Welcome to IT Certifications 101! What’s the...\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af060646",
   "metadata": {},
   "source": [
    "#### Step 1: Convert all text to lower for normalcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9cfe192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "what are the math and stats principles you need for data science?oct 21, 2020 | data science\n",
      "\n",
      "\n",
      "coming into our data science program, you will need to know some math and stats. however, many of our applicants actually learn in the application process – you don’t need to be an expert before applying! data science is a very accessible field to anyone dedicated to learning new skills, and we can work with any applicant to help them learn what they need to know. but what “skills” do we mean, exactly? just what exactly are the data science math and stats principles you need to know?\n",
      "what are the main math principles you need to know to get into codeup’s data science program?\n",
      "\n",
      "\n",
      "algebra\n",
      "do you know pemdas and can you solve for x? you will need to be or become comfortable with the following:\n",
      "\n",
      "variables (x, y, n, etc.)\n",
      "formulas, functions, and variable manipulations (e.g. x^2 = x + 6, solve for x).\n",
      "order of evaluation: pemdas: parentheses, exponents, then multiplication, division, addition, and subtraction\n",
      "commutativity where a + b = b + a\n",
      "associativity where a + (b + c) = (a + b) + c\n",
      "adding and subtracting matrices\n",
      "a conceptual understanding of exponential growth/decay- things can increase at an increasing rate\n",
      "\n",
      "descriptive statistics\n",
      "know what a min, max, mode, median, and average are. have a conceptual understanding that stats/probability is about trying to quantify uncertainty.\n",
      "data visualization\n",
      "know what a scatterplot is and how to read a barplot.\n",
      "how to learn and expand on these concepts\n",
      "there are a number of great resources out there to teach you these and similar concepts. khan academy is a great starting place for data science math! if you want to know what exactly we assign our applicants, you’ll just have to apply!\n",
      " \n",
      "what about once you’re in codeup?\n",
      "\n",
      "\n",
      "what you won’t do\n",
      "do we do any mathematical proofs for concepts or perform derivations? no. \n",
      "do we do any calculus and probability calculating by hand? no.\n",
      "are we transforming equations, where we cancel out units or terms and do lots of algebraic gymnastics? no\n",
      "what you will do\n",
      "will we have python solve our linear algebra problems for us? yes\n",
      "will we have python calculate probabilities, the area under a curve, and the slope of a line for us? yes\n",
      "will we have python do all of the calculus for us? yes\n",
      " \n",
      "see, the data science math and stats slice of the pie is certainly doable. if you like problem-solving and are ready to challenge yourself, you’ll love data science! if you are interested in learning about data science, just apply! our admissions manager can work with you to get you where you need to be starting from where you are now. let us help you get there so you can launch a great new career.\n",
      "\n",
      "request more info\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "our programsfull stack web development\n",
      "data science\n",
      "cyber cloud\n",
      "systems engineering\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "latest blog articles\n",
      "codeup dallas open house\n",
      "codeup’s placement team continues setting records\n",
      "it certifications 101: why they matter, and why they don’t\n",
      "a rise in cyber attacks means opportunities for veterans in san antonio\n",
      "use your gi bill® benefits to land a job in tech\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "more from this category\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeup dallas open house\n",
      "nov 30, 2021 | dallas newsletter, eventscome join us for the re-opening of our dallas campus with some drinks and snacks at codeup! curious about what our campus looks like? click here to register for free about this event come join us for the re-opening of our dallas campus with some drinks and snacks at...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeup’s placement team continues setting records\n",
      "nov 19, 2021 | codeup news, employersour placement team is simply defined as a group that manages relationships with our employer partners and our graduating students to help get our graduating students hired. last quarter the placement team helped 48 students get hired to life-changing careers in tech....\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it certifications 101: why they matter, and why they don’t\n",
      "nov 18, 2021 | cybersecurity, it training, tips for prospective studentsaws, google, azure, red hat, comptia...these are big names in it! and not only for their products, but also for the certifications they offer. if you’re new to tech, you might be wondering: do certifications really matter? welcome to it certifications 101! what’s the...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article = original.lower()\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8e3823",
   "metadata": {},
   "source": [
    "#### Step 2: Remove any accented characters, non-ASCII characters.\n",
    "\n",
    "Usually in any text corpus, you might be dealing with accented characters/letters, especially if you only want to analyze the English language. Hence, we need to make sure that these characters are converted and standardized into ASCII characters. A simple example is converting é to e.\n",
    "\n",
    "We'll go about this in three steps:\n",
    "\n",
    "1. `unicodedata.normalize` removes any inconsistencies in unicode character encoding.\n",
    "1. `.encode` to convert the resulting string to the ASCII character set. We'll ignore any errors in conversion, meaning we'll drop anything that isn't an ASCII character.\n",
    "1. `.decode` to turn the resulting bytes object back into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "228c3ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "what are the math and stats principles you need for data science?oct 21, 2020 | data science\n",
      "\n",
      "\n",
      "coming into our data science program, you will need to know some math and stats. however, many of our applicants actually learn in the application process  you dont need to be an expert before applying! data science is a very accessible field to anyone dedicated to learning new skills, and we can work with any applicant to help them learn what they need to know. but what skills do we mean, exactly? just what exactly are the data science math and stats principles you need to know?\n",
      "what are the main math principles you need to know to get into codeups data science program?\n",
      "\n",
      "\n",
      "algebra\n",
      "do you know pemdas and can you solve for x? you will need to be or become comfortable with the following:\n",
      "\n",
      "variables (x, y, n, etc.)\n",
      "formulas, functions, and variable manipulations (e.g. x^2 = x + 6, solve for x).\n",
      "order of evaluation: pemdas: parentheses, exponents, then multiplication, division, addition, and subtraction\n",
      "commutativity where a + b = b + a\n",
      "associativity where a + (b + c) = (a + b) + c\n",
      "adding and subtracting matrices\n",
      "a conceptual understanding of exponential growth/decay- things can increase at an increasing rate\n",
      "\n",
      "descriptive statistics\n",
      "know what a min, max, mode, median, and average are. have a conceptual understanding that stats/probability is about trying to quantify uncertainty.\n",
      "data visualization\n",
      "know what a scatterplot is and how to read a barplot.\n",
      "how to learn and expand on these concepts\n",
      "there are a number of great resources out there to teach you these and similar concepts. khan academy is a great starting place for data science math! if you want to know what exactly we assign our applicants, youll just have to apply!\n",
      " \n",
      "what about once youre in codeup?\n",
      "\n",
      "\n",
      "what you wont do\n",
      "do we do any mathematical proofs for concepts or perform derivations? no. \n",
      "do we do any calculus and probability calculating by hand? no.\n",
      "are we transforming equations, where we cancel out units or terms and do lots of algebraic gymnastics? no\n",
      "what you will do\n",
      "will we have python solve our linear algebra problems for us? yes\n",
      "will we have python calculate probabilities, the area under a curve, and the slope of a line for us? yes\n",
      "will we have python do all of the calculus for us? yes\n",
      " \n",
      "see, the data science math and stats slice of the pie is certainly doable. if you like problem-solving and are ready to challenge yourself, youll love data science! if you are interested in learning about data science, just apply! our admissions manager can work with you to get you where you need to be starting from where you are now. let us help you get there so you can launch a great new career.\n",
      "\n",
      "request more info\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "our programsfull stack web development\n",
      "data science\n",
      "cyber cloud\n",
      "systems engineering\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "latest blog articles\n",
      "codeup dallas open house\n",
      "codeups placement team continues setting records\n",
      "it certifications 101: why they matter, and why they dont\n",
      "a rise in cyber attacks means opportunities for veterans in san antonio\n",
      "use your gi bill benefits to land a job in tech\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "more from this category\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeup dallas open house\n",
      "nov 30, 2021 | dallas newsletter, eventscome join us for the re-opening of our dallas campus with some drinks and snacks at codeup! curious about what our campus looks like? click here to register for free about this event come join us for the re-opening of our dallas campus with some drinks and snacks at...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeups placement team continues setting records\n",
      "nov 19, 2021 | codeup news, employersour placement team is simply defined as a group that manages relationships with our employer partners and our graduating students to help get our graduating students hired. last quarter the placement team helped 48 students get hired to life-changing careers in tech....\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it certifications 101: why they matter, and why they dont\n",
      "nov 18, 2021 | cybersecurity, it training, tips for prospective studentsaws, google, azure, red hat, comptia...these are big names in it! and not only for their products, but also for the certifications they offer. if youre new to tech, you might be wondering: do certifications really matter? welcome to it certifications 101! whats the...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "article = unicodedata.normalize('NFKD', article)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496ecea",
   "metadata": {},
   "source": [
    "#### Step 3: Remove special characters\n",
    "\n",
    "Special characters and symbols are usually non-alphanumeric characters or even occasionally numeric characters (depending on the problem), which add to the extra noise in unstructured text. Usually, simple regular expressions (regexes) can be used to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e886940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "what are the math and stats principles you need for data scienceoct 21 2020  data science\n",
      "\n",
      "\n",
      "coming into our data science program you will need to know some math and stats however many of our applicants actually learn in the application process  you dont need to be an expert before applying data science is a very accessible field to anyone dedicated to learning new skills and we can work with any applicant to help them learn what they need to know but what skills do we mean exactly just what exactly are the data science math and stats principles you need to know\n",
      "what are the main math principles you need to know to get into codeups data science program\n",
      "\n",
      "\n",
      "algebra\n",
      "do you know pemdas and can you solve for x you will need to be or become comfortable with the following\n",
      "\n",
      "variables x y n etc\n",
      "formulas functions and variable manipulations eg x2  x  6 solve for x\n",
      "order of evaluation pemdas parentheses exponents then multiplication division addition and subtraction\n",
      "commutativity where a  b  b  a\n",
      "associativity where a  b  c  a  b  c\n",
      "adding and subtracting matrices\n",
      "a conceptual understanding of exponential growthdecay things can increase at an increasing rate\n",
      "\n",
      "descriptive statistics\n",
      "know what a min max mode median and average are have a conceptual understanding that statsprobability is about trying to quantify uncertainty\n",
      "data visualization\n",
      "know what a scatterplot is and how to read a barplot\n",
      "how to learn and expand on these concepts\n",
      "there are a number of great resources out there to teach you these and similar concepts khan academy is a great starting place for data science math if you want to know what exactly we assign our applicants youll just have to apply\n",
      " \n",
      "what about once youre in codeup\n",
      "\n",
      "\n",
      "what you wont do\n",
      "do we do any mathematical proofs for concepts or perform derivations no \n",
      "do we do any calculus and probability calculating by hand no\n",
      "are we transforming equations where we cancel out units or terms and do lots of algebraic gymnastics no\n",
      "what you will do\n",
      "will we have python solve our linear algebra problems for us yes\n",
      "will we have python calculate probabilities the area under a curve and the slope of a line for us yes\n",
      "will we have python do all of the calculus for us yes\n",
      " \n",
      "see the data science math and stats slice of the pie is certainly doable if you like problemsolving and are ready to challenge yourself youll love data science if you are interested in learning about data science just apply our admissions manager can work with you to get you where you need to be starting from where you are now let us help you get there so you can launch a great new career\n",
      "\n",
      "request more info\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "our programsfull stack web development\n",
      "data science\n",
      "cyber cloud\n",
      "systems engineering\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "latest blog articles\n",
      "codeup dallas open house\n",
      "codeups placement team continues setting records\n",
      "it certifications 101 why they matter and why they dont\n",
      "a rise in cyber attacks means opportunities for veterans in san antonio\n",
      "use your gi bill benefits to land a job in tech\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "more from this category\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeup dallas open house\n",
      "nov 30 2021  dallas newsletter eventscome join us for the reopening of our dallas campus with some drinks and snacks at codeup curious about what our campus looks like click here to register for free about this event come join us for the reopening of our dallas campus with some drinks and snacks at\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeups placement team continues setting records\n",
      "nov 19 2021  codeup news employersour placement team is simply defined as a group that manages relationships with our employer partners and our graduating students to help get our graduating students hired last quarter the placement team helped 48 students get hired to lifechanging careers in tech\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it certifications 101 why they matter and why they dont\n",
      "nov 18 2021  cybersecurity it training tips for prospective studentsaws google azure red hat comptiathese are big names in it and not only for their products but also for the certifications they offer if youre new to tech you might be wondering do certifications really matter welcome to it certifications 101 whats the\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove anything that is not a through z, a number, a single quote, or whitespace\n",
    "article = re.sub(r\"[^a-z0-9'\\s]\", '', article)\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d33fac4",
   "metadata": {},
   "source": [
    "#### Step 4: Tokenization\n",
    "\n",
    "After removing non-ASCII characters and special characters, it's common to tokenize the strings, to break words and any punctuation left over into discrete units. Tokenization is the process of breaking something down into discrete units. In the context of NLP, this means breaking text down into discrete words, punctuation, etc.\n",
    "\n",
    "We will use `nltk` to do tokenization for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0e4d855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the math and stats principles you need for data scienceoct 21 2020 data science\n",
      "\n",
      "\n",
      "coming into our data science program you will need to know some math and stats however many of our applicants actually learn in the application process you dont need to be an expert before applying data science is a very accessible field to anyone dedicated to learning new skills and we can work with any applicant to help them learn what they need to know but what skills do we mean exactly just what exactly are the data science math and stats principles you need to know\n",
      "what are the main math principles you need to know to get into codeups data science program\n",
      "\n",
      "\n",
      "algebra\n",
      "do you know pemdas and can you solve for x you will need to be or become comfortable with the following\n",
      "\n",
      "variables x y n etc\n",
      "formulas functions and variable manipulations eg x2 x 6 solve for x\n",
      "order of evaluation pemdas parentheses exponents then multiplication division addition and subtraction\n",
      "commutativity where a b b a\n",
      "associativity where a b c a b c\n",
      "adding and subtracting matrices\n",
      "a conceptual understanding of exponential growthdecay things can increase at an increasing rate\n",
      "\n",
      "descriptive statistics\n",
      "know what a min max mode median and average are have a conceptual understanding that statsprobability is about trying to quantify uncertainty\n",
      "data visualization\n",
      "know what a scatterplot is and how to read a barplot\n",
      "how to learn and expand on these concepts\n",
      "there are a number of great resources out there to teach you these and similar concepts khan academy is a great starting place for data science math if you want to know what exactly we assign our applicants youll just have to apply\n",
      " \n",
      "what about once youre in codeup\n",
      "\n",
      "\n",
      "what you wont do\n",
      "do we do any mathematical proofs for concepts or perform derivations no \n",
      "do we do any calculus and probability calculating by hand no\n",
      "are we transforming equations where we cancel out units or terms and do lots of algebraic gymnastics no\n",
      "what you will do\n",
      "will we have python solve our linear algebra problems for us yes\n",
      "will we have python calculate probabilities the area under a curve and the slope of a line for us yes\n",
      "will we have python do all of the calculus for us yes\n",
      " \n",
      "see the data science math and stats slice of the pie is certainly doable if you like problemsolving and are ready to challenge yourself youll love data science if you are interested in learning about data science just apply our admissions manager can work with you to get you where you need to be starting from where you are now let us help you get there so you can launch a great new career\n",
      "\n",
      "request more info\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "our programsfull stack web development\n",
      "data science\n",
      "cyber cloud\n",
      "systems engineering\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "latest blog articles\n",
      "codeup dallas open house\n",
      "codeups placement team continues setting records\n",
      "it certifications 101 why they matter and why they dont\n",
      "a rise in cyber attacks means opportunities for veterans in san antonio\n",
      "use your gi bill benefits to land a job in tech\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "more from this category\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeup dallas open house\n",
      "nov 30 2021 dallas newsletter eventscome join us for the reopening of our dallas campus with some drinks and snacks at codeup curious about what our campus looks like click here to register for free about this event come join us for the reopening of our dallas campus with some drinks and snacks at\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "codeups placement team continues setting records\n",
      "nov 19 2021 codeup news employersour placement team is simply defined as a group that manages relationships with our employer partners and our graduating students to help get our graduating students hired last quarter the placement team helped 48 students get hired to lifechanging careers in tech\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it certifications 101 why they matter and why they dont\n",
      "nov 18 2021 cybersecurity it training tips for prospective studentsaws google azure red hat comptiathese are big names in it and not only for their products but also for the certifications they offer if youre new to tech you might be wondering do certifications really matter welcome to it certifications 101 whats the\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(article, return_str=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d89f6a4",
   "metadata": {},
   "source": [
    "#### Step 5: Stemming and Lemmatization\n",
    "\n",
    "Usually you will want to use lemmatization. We will demonstrate why that is the case by looking at both here.\n",
    "\n",
    "#### Stemming:\n",
    "Word stems are the base form of a word.\n",
    "\n",
    "We create new words by attaching affixes in a process known as inflection. For example, \"calls\", \"called\", and \"calling\" all share the base stem \"call\".\n",
    "\n",
    "The Porter stemmer is based on the algorithm developed by its inventor, Dr. Martin Porter. Originally, the algorithm is said to have had a total of five different phases for reduction of inflections to their stems, where each phase has its own set of rules.\n",
    "\n",
    "Note that usually stemming has a fixed set of rules, hence, the root stems may not be lexicographically correct. This means that the stemmed words may not be semantically correct, and might have a chance of not being present in the dictionary (as we'll see in the output of stemming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02349d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('catch', 'caught', 'catch')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the nltk stemmer object, then use it\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "ps.stem('catching'), ps.stem('caught'), ps.stem('catch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23821fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d0849fe",
   "metadata": {},
   "source": [
    "Now we can apply this stemming transformation to all the words in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1abc48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the math and stat principl you need for data scienceoct 21 2020 data scienc come into our data scienc program you will need to know some math and stat howev mani of our applic actual learn in the applic process you dont need to be an expert befor appli data scienc is a veri access field to anyon dedic to learn new skill and we can work with ani applic to help them learn what they need to know but what skill do we mean exactli just what exactli are the data scienc math and stat principl you need to know what are the main math principl you need to know to get into codeup data scienc program algebra do you know pemda and can you solv for x you will need to be or becom comfort with the follow variabl x y n etc formula function and variabl manipul eg x2 x 6 solv for x order of evalu pemda parenthes expon then multipl divis addit and subtract commut where a b b a associ where a b c a b c ad and subtract matric a conceptu understand of exponenti growthdecay thing can increas at an increas rate descript statist know what a min max mode median and averag are have a conceptu understand that statsprob is about tri to quantifi uncertainti data visual know what a scatterplot is and how to read a barplot how to learn and expand on these concept there are a number of great resourc out there to teach you these and similar concept khan academi is a great start place for data scienc math if you want to know what exactli we assign our applic youll just have to appli what about onc your in codeup what you wont do do we do ani mathemat proof for concept or perform deriv no do we do ani calculu and probabl calcul by hand no are we transform equat where we cancel out unit or term and do lot of algebra gymnast no what you will do will we have python solv our linear algebra problem for us ye will we have python calcul probabl the area under a curv and the slope of a line for us ye will we have python do all of the calculu for us ye see the data scienc math and stat slice of the pie is certainli doabl if you like problemsolv and are readi to challeng yourself youll love data scienc if you are interest in learn about data scienc just appli our admiss manag can work with you to get you where you need to be start from where you are now let us help you get there so you can launch a great new career request more info our programsful stack web develop data scienc cyber cloud system engin latest blog articl codeup dalla open hous codeup placement team continu set record it certif 101 whi they matter and whi they dont a rise in cyber attack mean opportun for veteran in san antonio use your gi bill benefit to land a job in tech more from thi categori codeup dalla open hous nov 30 2021 dalla newslett eventscom join us for the reopen of our dalla campu with some drink and snack at codeup curiou about what our campu look like click here to regist for free about thi event come join us for the reopen of our dalla campu with some drink and snack at codeup placement team continu set record nov 19 2021 codeup news employersour placement team is simpli defin as a group that manag relationship with our employ partner and our graduat student to help get our graduat student hire last quarter the placement team help 48 student get hire to lifechang career in tech it certif 101 whi they matter and whi they dont nov 18 2021 cybersecur it train tip for prospect studentsaw googl azur red hat comptiathes are big name in it and not onli for their product but also for the certif they offer if your new to tech you might be wonder do certif realli matter welcom to it certif 101 what the\n"
     ]
    }
   ],
   "source": [
    "stems = [ps.stem(word) for word in article.split()]\n",
    "article_stemmed = ' '.join(stems)\n",
    "print(article_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb6383f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to      25\n",
       "and     23\n",
       "you     21\n",
       "a       18\n",
       "the     15\n",
       "for     15\n",
       "what    13\n",
       "data    12\n",
       "our     12\n",
       "do      11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(stems).value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b51168",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "Lemmatization is very similar to stemming, however, the base form in this case is known as the root word, but not the root stem. The difference is that the root word is always a lexicographically correct word (present in the dictionary), but the root stem may not be so. Thus, root word, also known as the lemma, will always be present in the dictionary.\n",
    "\n",
    "Note that the lemmatization process is considerably slower than stemming, because an additional step is involved where the root form or lemma is formed by removing the affix from the word if and only if the lemma is present in the dictionary.\n",
    "\n",
    "Let's take a look at a simple example of the difference between stemming and lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcd0f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 -c \"import nltk; nltk.download('all')\"\n",
    "# OR\n",
    "# python3 -c \"import nltk; nltk.download('wordnet')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc277fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem: studi -- lemma: study\n",
      "stem: studi -- lemma: study\n"
     ]
    }
   ],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "for word in 'study studies'.split():\n",
    "    print('stem:', ps.stem(word), '-- lemma:', wnl.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b065a5c3",
   "metadata": {},
   "source": [
    "And now we can apply lemmatization to our entire document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7112e41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the math and stats principle you need for data scienceoct 21 2020 data science coming into our data science program you will need to know some math and stats however many of our applicant actually learn in the application process you dont need to be an expert before applying data science is a very accessible field to anyone dedicated to learning new skill and we can work with any applicant to help them learn what they need to know but what skill do we mean exactly just what exactly are the data science math and stats principle you need to know what are the main math principle you need to know to get into codeups data science program algebra do you know pemdas and can you solve for x you will need to be or become comfortable with the following variable x y n etc formula function and variable manipulation eg x2 x 6 solve for x order of evaluation pemdas parenthesis exponent then multiplication division addition and subtraction commutativity where a b b a associativity where a b c a b c adding and subtracting matrix a conceptual understanding of exponential growthdecay thing can increase at an increasing rate descriptive statistic know what a min max mode median and average are have a conceptual understanding that statsprobability is about trying to quantify uncertainty data visualization know what a scatterplot is and how to read a barplot how to learn and expand on these concept there are a number of great resource out there to teach you these and similar concept khan academy is a great starting place for data science math if you want to know what exactly we assign our applicant youll just have to apply what about once youre in codeup what you wont do do we do any mathematical proof for concept or perform derivation no do we do any calculus and probability calculating by hand no are we transforming equation where we cancel out unit or term and do lot of algebraic gymnastics no what you will do will we have python solve our linear algebra problem for u yes will we have python calculate probability the area under a curve and the slope of a line for u yes will we have python do all of the calculus for u yes see the data science math and stats slice of the pie is certainly doable if you like problemsolving and are ready to challenge yourself youll love data science if you are interested in learning about data science just apply our admission manager can work with you to get you where you need to be starting from where you are now let u help you get there so you can launch a great new career request more info our programsfull stack web development data science cyber cloud system engineering latest blog article codeup dallas open house codeups placement team continues setting record it certification 101 why they matter and why they dont a rise in cyber attack mean opportunity for veteran in san antonio use your gi bill benefit to land a job in tech more from this category codeup dallas open house nov 30 2021 dallas newsletter eventscome join u for the reopening of our dallas campus with some drink and snack at codeup curious about what our campus look like click here to register for free about this event come join u for the reopening of our dallas campus with some drink and snack at codeups placement team continues setting record nov 19 2021 codeup news employersour placement team is simply defined a a group that manages relationship with our employer partner and our graduating student to help get our graduating student hired last quarter the placement team helped 48 student get hired to lifechanging career in tech it certification 101 why they matter and why they dont nov 18 2021 cybersecurity it training tip for prospective studentsaws google azure red hat comptiathese are big name in it and not only for their product but also for the certification they offer if youre new to tech you might be wondering do certification really matter welcome to it certification 101 whats the\n"
     ]
    }
   ],
   "source": [
    "lemmas = [wnl.lemmatize(word) for word in article.split()]\n",
    "article_lemmatized = ' '.join(lemmas)\n",
    "\n",
    "print(article_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3df52",
   "metadata": {},
   "source": [
    "Now that we have a list of the lemmas, we can take a look at the most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee698345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to      25\n",
       "and     23\n",
       "you     21\n",
       "a       19\n",
       "for     15\n",
       "the     15\n",
       "data    12\n",
       "our     12\n",
       "what    12\n",
       "do      11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lemmas).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98721359",
   "metadata": {},
   "source": [
    "#### Step 6: Removing stopwords\n",
    "\n",
    "Words which have little or no significance, especially when constructing meaningful features from text, are known as stop words (or stopwords). These are usually words that end up having the maximum frequency if you do a simple term or word frequency in a corpus. Typically, these can be articles, conjunctions, prepositions and so on. Some examples of stopwords: a, an, the, and like.\n",
    "\n",
    "While there is no universal stopword list, we will use a standard English language stopwords list from nltk. You can also add your own domain-specific stopwords as needed.\n",
    "\n",
    "Before removing stopwords, we want to segment text into linguistic units such as words or numbers. This process is called tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bf65e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "stopword_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a707494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e81f1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 307 stopwords\n",
      "---\n",
      "math stats principles need data scienceoct 21 2020 data science coming data science program need know math stats however many applicants actually learn application process dont need expert applying data science accessible field anyone dedicated learning new skills work applicant help learn need know skills mean exactly exactly data science math stats principles need know main math principles need know get codeups data science program algebra know pemdas solve x need become comfortable following variables x n etc formulas functions variable manipulations eg x2 x 6 solve x order evaluation pemdas parentheses exponents multiplication division addition subtraction commutativity b b associativity b c b c adding subtracting matrices conceptual understanding exponential growthdecay things increase increasing rate descriptive statistics know min max mode median average conceptual understanding statsprobability trying quantify uncertainty data visualization know scatterplot read barplot learn expand concepts number great resources teach similar concepts khan academy great starting place data science math want know exactly assign applicants youll apply youre codeup wont mathematical proofs concepts perform derivations no calculus probability calculating hand no transforming equations cancel units terms lots algebraic gymnastics no python solve linear algebra problems us yes python calculate probabilities area curve slope line us yes python calculus us yes see data science math stats slice pie certainly doable like problemsolving ready challenge youll love data science interested learning data science apply admissions manager work get need starting let us help get launch great new career request info programsfull stack web development data science cyber cloud systems engineering latest blog articles codeup dallas open house codeups placement team continues setting records certifications 101 matter dont rise cyber attacks means opportunities veterans san antonio use gi bill benefits land job tech category codeup dallas open house nov 30 2021 dallas newsletter eventscome join us reopening dallas campus drinks snacks codeup curious campus looks like click register free event come join us reopening dallas campus drinks snacks codeups placement team continues setting records nov 19 2021 codeup news employersour placement team simply defined group manages relationships employer partners graduating students help get graduating students hired last quarter placement team helped 48 students get hired lifechanging careers tech certifications 101 matter dont nov 18 2021 cybersecurity training tips prospective studentsaws google azure red hat comptiathese big names not products also certifications offer youre new tech might wondering certifications really matter welcome certifications 101 whats\n"
     ]
    }
   ],
   "source": [
    "words = article.split()\n",
    "filtered_words = [w for w in words if w not in stopword_list]\n",
    "\n",
    "print('Removed {} stopwords'.format(len(words) - len(filtered_words)))\n",
    "print('---')\n",
    "\n",
    "article_without_stopwords = ' '.join(filtered_words)\n",
    "\n",
    "print(article_without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18694dfa",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "The end result of this exercise should be a file named `prepare.py` that defines the requested functions.\n",
    "\n",
    "In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired.\n",
    "\n",
    "1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "339276e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e6b84f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_published</th>\n",
       "      <th>article_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>Jan 26, 2022</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VET TEC Funding Now Available For Dallas Veterans</td>\n",
       "      <td>Jan 7, 2022</td>\n",
       "      <td>We are so happy to announce that VET TEC benef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dallas Campus Re-opens With New Grant Partner</td>\n",
       "      <td>Dec 30, 2021</td>\n",
       "      <td>We are happy to announce that our Dallas campu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Codeup Dallas Open House</td>\n",
       "      <td>Nov 30, 2021</td>\n",
       "      <td>Come join us for the re-opening of our Dallas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codeup’s Placement Team Continues Setting Records</td>\n",
       "      <td>Nov 19, 2021</td>\n",
       "      <td>Our Placement Team is simply defined as a grou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title date_published  \\\n",
       "0                  Codeup Start Dates for March 2022   Jan 26, 2022   \n",
       "1  VET TEC Funding Now Available For Dallas Veterans    Jan 7, 2022   \n",
       "2      Dallas Campus Re-opens With New Grant Partner   Dec 30, 2021   \n",
       "3                           Codeup Dallas Open House   Nov 30, 2021   \n",
       "4  Codeup’s Placement Team Continues Setting Records   Nov 19, 2021   \n",
       "\n",
       "                                     article_content  \n",
       "0  As we approach the end of January we wanted to...  \n",
       "1  We are so happy to announce that VET TEC benef...  \n",
       "2  We are happy to announce that our Dallas campu...  \n",
       "3  Come join us for the re-opening of our Dallas ...  \n",
       "4  Our Placement Team is simply defined as a grou...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs = acquire.get_blog_articles(cached=True)\n",
    "blogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0c2787c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'date_published', 'article_content'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blogs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac959d",
   "metadata": {},
   "source": [
    "# OK NEW APPROACH: ONLY WORK ON THE ARTICLE_CONTENTS COLUMN, LEAVE THE REST BE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e63f7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original = blogs.article_content\n",
    "# original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73247597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# original = re.sub(r\"[^a-z0-9'\\s]\", '', original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b128661",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# original = original.str.lower().replace(r'[^\\w\\s]', '', regex=True).str.normalize('NFKD').str.encode('ascii', 'ignore').str.decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "173e742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(df,col):\n",
    "    df['clean'] = df[col].str.lower().replace(r'[^\\w\\s]', '', regex=True)\\\n",
    "    .str.normalize('NFKD').str.encode('ascii', 'ignore').str.decode('utf-8', 'ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d45935b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = basic_clean(blogs,'article_content')\n",
    "# test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4943e9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_published</th>\n",
       "      <th>article_content</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>Jan 26, 2022</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "      <td>as we approach the end of january we wanted to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VET TEC Funding Now Available For Dallas Veterans</td>\n",
       "      <td>Jan 7, 2022</td>\n",
       "      <td>We are so happy to announce that VET TEC benef...</td>\n",
       "      <td>we are so happy to announce that vet tec benef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title date_published  \\\n",
       "0                  Codeup Start Dates for March 2022   Jan 26, 2022   \n",
       "1  VET TEC Funding Now Available For Dallas Veterans    Jan 7, 2022   \n",
       "\n",
       "                                     article_content  \\\n",
       "0  As we approach the end of January we wanted to...   \n",
       "1  We are so happy to announce that VET TEC benef...   \n",
       "\n",
       "                                               clean  \n",
       "0  as we approach the end of january we wanted to...  \n",
       "1  we are so happy to announce that vet tec benef...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b335b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in blogs.columns:\n",
    "#     blogs[col] = blogs[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4c05e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in blogs.columns:\n",
    "#     blogs[col] = blogs[col].str.normalize('NFKD')\\\n",
    "#     .str.encode('ascii', 'ignore')\\\n",
    "#     .str.decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd2fbb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in blogs.columns:\n",
    "#     blogs[col] = blogs[col].replace(r\"[^a-z0-9'\\s]\", '',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7c924",
   "metadata": {},
   "source": [
    "### ok the new approach is looking more promising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e872f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def basic_clean(df):\n",
    "#     for col in df.columns:\n",
    "#         df[col] = df[col].str.lower().str.normalize('NFKD')\\\n",
    "#         .str.encode('ascii', 'ignore')\\\n",
    "#         .str.decode('utf-8', 'ignore')\\\n",
    "#         .replace(r\"[^a-z0-9'\\s]\", '',regex=True)\n",
    "#     return df\n",
    "\n",
    "# # even better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "055d2998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blogs = acquire.get_blog_articles(cached=True)\n",
    "# blogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd33b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blogs = basic_clean(blogs)\n",
    "# blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1518e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30fd16bb",
   "metadata": {},
   "source": [
    "2. Define a function named `tokenize`. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dff18a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "# print(tokenizer.tokenize(blogs, return_str=True))\n",
    "# for col in blogs.columns:\n",
    "#     blogs[col] = blogs[col].apply(tokenizer.tokenize)\n",
    "# #     blogs.reset_index()\n",
    "# blogs.head()\n",
    "# [tokenizer.tokenize(blogs[col], return_str=True) for col in blogs.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25de6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df,col):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    df[col] = df[col].apply(tokenizer.tokenize)\n",
    "#     df[col] = df[col].str.join(' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9af47eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blogs = tokenize(blogs)\n",
    "# blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed02d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = tokenize(blogs,'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adef3b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_published</th>\n",
       "      <th>article_content</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>Jan 26, 2022</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "      <td>[as, we, approach, the, end, of, january, we, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VET TEC Funding Now Available For Dallas Veterans</td>\n",
       "      <td>Jan 7, 2022</td>\n",
       "      <td>We are so happy to announce that VET TEC benef...</td>\n",
       "      <td>[we, are, so, happy, to, announce, that, vet, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title date_published  \\\n",
       "0                  Codeup Start Dates for March 2022   Jan 26, 2022   \n",
       "1  VET TEC Funding Now Available For Dallas Veterans    Jan 7, 2022   \n",
       "\n",
       "                                     article_content  \\\n",
       "0  As we approach the end of January we wanted to...   \n",
       "1  We are so happy to announce that VET TEC benef...   \n",
       "\n",
       "                                               clean  \n",
       "0  [as, we, approach, the, end, of, january, we, ...  \n",
       "1  [we, are, so, happy, to, announce, that, vet, ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04756b0",
   "metadata": {},
   "source": [
    "we end up with a list in the 'clean' column.  we would have to join the strings in the list into one string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527bce5",
   "metadata": {},
   "source": [
    "3. Define a function named `stem`. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6c0b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the nltk stemmer object, then use it\n",
    "ps = nltk.porter.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38f871e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(df,col):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = df[col].apply(lambda row: [ps.stem(word) for word in row])\n",
    "    df['stemmed'] = stems.str.join(' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e74fb0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_published</th>\n",
       "      <th>article_content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>Jan 26, 2022</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "      <td>[as, we, approach, the, end, of, january, we, ...</td>\n",
       "      <td>a s   w e   a p p r o a c h   t h e   e n d   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VET TEC Funding Now Available For Dallas Veterans</td>\n",
       "      <td>Jan 7, 2022</td>\n",
       "      <td>We are so happy to announce that VET TEC benef...</td>\n",
       "      <td>[we, are, so, happy, to, announce, that, vet, ...</td>\n",
       "      <td>w e   a r e   s o   h a p p y   t o   a n n o ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title date_published  \\\n",
       "0                  Codeup Start Dates for March 2022   Jan 26, 2022   \n",
       "1  VET TEC Funding Now Available For Dallas Veterans    Jan 7, 2022   \n",
       "\n",
       "                                     article_content  \\\n",
       "0  As we approach the end of January we wanted to...   \n",
       "1  We are so happy to announce that VET TEC benef...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  [as, we, approach, the, end, of, january, we, ...   \n",
       "1  [we, are, so, happy, to, announce, that, vet, ...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  a s   w e   a p p r o a c h   t h e   e n d   ...  \n",
       "1  w e   a r e   s o   h a p p y   t o   a n n o ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3 = stem(blogs,'article_content')\n",
    "test3.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32656b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32bd9b4b",
   "metadata": {},
   "source": [
    "4. Define a function named `lemmatize`. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b8cc88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce87cc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(df,col):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = df[col].apply(lambda row: [wnl.lemmatize(word) for word in row])\n",
    "    df['lemmatized'] = lemmas.str.join(' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae9db37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_published</th>\n",
       "      <th>article_content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>Jan 26, 2022</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "      <td>[as, we, approach, the, end, of, january, we, ...</td>\n",
       "      <td>a s   w e   a p p r o a c h   t h e   e n d   ...</td>\n",
       "      <td>A s   w e   a p p r o a c h   t h e   e n d   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VET TEC Funding Now Available For Dallas Veterans</td>\n",
       "      <td>Jan 7, 2022</td>\n",
       "      <td>We are so happy to announce that VET TEC benef...</td>\n",
       "      <td>[we, are, so, happy, to, announce, that, vet, ...</td>\n",
       "      <td>w e   a r e   s o   h a p p y   t o   a n n o ...</td>\n",
       "      <td>W e   a r e   s o   h a p p y   t o   a n n o ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title date_published  \\\n",
       "0                  Codeup Start Dates for March 2022   Jan 26, 2022   \n",
       "1  VET TEC Funding Now Available For Dallas Veterans    Jan 7, 2022   \n",
       "\n",
       "                                     article_content  \\\n",
       "0  As we approach the end of January we wanted to...   \n",
       "1  We are so happy to announce that VET TEC benef...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  [as, we, approach, the, end, of, january, we, ...   \n",
       "1  [we, are, so, happy, to, announce, that, vet, ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  a s   w e   a p p r o a c h   t h e   e n d   ...   \n",
       "1  w e   a r e   s o   h a p p y   t o   a n n o ...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  A s   w e   a p p r o a c h   t h e   e n d   ...  \n",
       "1  W e   a r e   s o   h a p p y   t o   a n n o ...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test4 = lemmatize(blogs,'article_content')\n",
    "test4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02203747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d383b88a",
   "metadata": {},
   "source": [
    "5. Define a function named `remove_stopwords`. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "    This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c95b3383",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2dc5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(df,col,extra_words=[],exclude_words=['no','not']):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    stopword_list.extend(extra_words)\n",
    "#     stopword_list = (set(stopword_list) - set(exclude_words))\n",
    "    for word in exclude_words:\n",
    "        if word not in stopword_list:\n",
    "            continue\n",
    "        else:\n",
    "            stopword_list = stopword_list.remove(word)\n",
    "#     words = df[col].str.split()\n",
    "    df[col] = df[col].apply(lambda row: \n",
    "                                 row.str.split(),axis=1)\n",
    "    df[col] = df[col].apply(lambda row:\n",
    "                                 [word for word in row if word not in stopword_list])\n",
    "    df[col] = df[col].str.join(' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b36a904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     Codeup Start Dates for March 2022\n",
      "1     VET TEC Funding Now Available For Dallas Veterans\n",
      "2         Dallas Campus Re-opens With New Grant Partner\n",
      "3                              Codeup Dallas Open House\n",
      "4     Codeup’s Placement Team Continues Setting Records\n",
      "5     IT Certifications 101: Why They Matter, and Wh...\n",
      "6     A rise in cyber attacks means opportunities fo...\n",
      "7      Use your GI Bill® benefits to Land a Job in Tech\n",
      "8     Which program is right for me: Cyber Security ...\n",
      "9                  What the Heck is System Engineering?\n",
      "10       From Speech Pathology to Business Intelligence\n",
      "11                        Boris – Behind the Billboards\n",
      "12    Is Codeup the Best Bootcamp in San Antonio…or ...\n",
      "13             Codeup Launches First Podcast: Hire Tech\n",
      "14          Why Should I Become a System Administrator?\n",
      "15          Announcing our Candidacy for Accreditation!\n",
      "16    Codeup Takes Over More of the Historic Vogue B...\n",
      "17    Inclusion at Codeup During Pride Month (and Al...\n",
      "Name: title, dtype: object\n",
      "0     Jan 26, 2022\n",
      "1      Jan 7, 2022\n",
      "2     Dec 30, 2021\n",
      "3     Nov 30, 2021\n",
      "4     Nov 19, 2021\n",
      "5     Nov 18, 2021\n",
      "6     Nov 17, 2021\n",
      "7      Nov 4, 2021\n",
      "8     Oct 28, 2021\n",
      "9     Oct 21, 2021\n",
      "10    Oct 18, 2021\n",
      "11     Oct 3, 2021\n",
      "12    Sep 16, 2021\n",
      "13    Aug 25, 2021\n",
      "14    Aug 23, 2021\n",
      "15    Jun 30, 2021\n",
      "16    Jun 21, 2021\n",
      "17     Jun 4, 2021\n",
      "Name: date_published, dtype: object\n",
      "0     As we approach the end of January we wanted to...\n",
      "1     We are so happy to announce that VET TEC benef...\n",
      "2     We are happy to announce that our Dallas campu...\n",
      "3     Come join us for the re-opening of our Dallas ...\n",
      "4     Our Placement Team is simply defined as a grou...\n",
      "5     AWS, Google, Azure, Red Hat, CompTIA…these are...\n",
      "6     In the last few months, the US has experienced...\n",
      "7     As the end of military service gets closer, ma...\n",
      "8     What IT Career should I choose?\\nIf you’re thi...\n",
      "9     Codeup offers a 13-week training program: Syst...\n",
      "10    By: Alicia Gonzalez\\nBefore Codeup, I was a ho...\n",
      "11                                                     \n",
      "12    Looking for the best data science bootcamp in ...\n",
      "13    Any podcast enthusiasts out there? We are plea...\n",
      "14    With so many tech careers in demand, why choos...\n",
      "15    Did you know that even though we’re an indepen...\n",
      "16    Codeup is moving into another floor of our His...\n",
      "17    Happy Pride Month! Pride Month is a dedicated ...\n",
      "Name: article_content, dtype: object\n",
      "0     [as, we, approach, the, end, of, january, we, ...\n",
      "1     [we, are, so, happy, to, announce, that, vet, ...\n",
      "2     [we, are, happy, to, announce, that, our, dall...\n",
      "3     [come, join, us, for, the, reopening, of, our,...\n",
      "4     [our, placement, team, is, simply, defined, as...\n",
      "5     [aws, google, azure, red, hat, comptiathese, a...\n",
      "6     [in, the, last, few, months, the, us, has, exp...\n",
      "7     [as, the, end, of, military, service, gets, cl...\n",
      "8     [what, it, career, should, i, choose, if, your...\n",
      "9     [codeup, offers, a, 13week, training, program,...\n",
      "10    [by, alicia, gonzalez, before, codeup, i, was,...\n",
      "11                                                   []\n",
      "12    [looking, for, the, best, data, science, bootc...\n",
      "13    [any, podcast, enthusiasts, out, there, we, ar...\n",
      "14    [with, so, many, tech, careers, in, demand, wh...\n",
      "15    [did, you, know, that, even, though, were, an,...\n",
      "16    [codeup, is, moving, into, another, floor, of,...\n",
      "17    [happy, pride, month, pride, month, is, a, ded...\n",
      "Name: clean, dtype: object\n",
      "0     a s   w e   a p p r o a c h   t h e   e n d   ...\n",
      "1     w e   a r e   s o   h a p p y   t o   a n n o ...\n",
      "2     w e   a r e   h a p p y   t o   a n n o u n c ...\n",
      "3     c o m e   j o i n   u s   f o r   t h e   r e ...\n",
      "4     o u r   p l a c e m e n t   t e a m   i s   s ...\n",
      "5     a w s ,   g o o g l e ,   a z u r e ,   r e d ...\n",
      "6     i n   t h e   l a s t   f e w   m o n t h s , ...\n",
      "7     a s   t h e   e n d   o f   m i l i t a r y   ...\n",
      "8     w h a t   i t   c a r e e r   s h o u l d   i ...\n",
      "9     c o d e u p   o f f e r s   a   1 3 - w e e k ...\n",
      "10    b y :   a l i c i a   g o n z a l e z \\n b e f...\n",
      "11                                                     \n",
      "12    l o o k i n g   f o r   t h e   b e s t   d a ...\n",
      "13    a n y   p o d c a s t   e n t h u s i a s t s ...\n",
      "14    w i t h   s o   m a n y   t e c h   c a r e e ...\n",
      "15    d i d   y o u   k n o w   t h a t   e v e n   ...\n",
      "16    c o d e u p   i s   m o v i n g   i n t o   a ...\n",
      "17    h a p p y   p r i d e   m o n t h !   p r i d ...\n",
      "Name: stemmed, dtype: object\n",
      "0     A s   w e   a p p r o a c h   t h e   e n d   ...\n",
      "1     W e   a r e   s o   h a p p y   t o   a n n o ...\n",
      "2     W e   a r e   h a p p y   t o   a n n o u n c ...\n",
      "3     C o m e   j o i n   u s   f o r   t h e   r e ...\n",
      "4     O u r   P l a c e m e n t   T e a m   i s   s ...\n",
      "5     A W S ,   G o o g l e ,   A z u r e ,   R e d ...\n",
      "6     I n   t h e   l a s t   f e w   m o n t h s , ...\n",
      "7     A s   t h e   e n d   o f   m i l i t a r y   ...\n",
      "8     W h a t   I T   C a r e e r   s h o u l d   I ...\n",
      "9     C o d e u p   o f f e r s   a   1 3 - w e e k ...\n",
      "10    B y :   A l i c i a   G o n z a l e z \\n B e f...\n",
      "11                                                     \n",
      "12    L o o k i n g   f o r   t h e   b e s t   d a ...\n",
      "13    A n y   p o d c a s t   e n t h u s i a s t s ...\n",
      "14    W i t h   s o   m a n y   t e c h   c a r e e ...\n",
      "15    D i d   y o u   k n o w   t h a t   e v e n   ...\n",
      "16    C o d e u p   i s   m o v i n g   i n t o   a ...\n",
      "17    H a p p y   P r i d e   M o n t h !   P r i d ...\n",
      "Name: lemmatized, dtype: object\n"
     ]
    }
   ],
   "source": [
    "blogs.article_content=blogs.apply(lambda row: print(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f576b59a",
   "metadata": {},
   "source": [
    "RAISING AN ERROR ON THE .REMOVE(); THE DOCSTRING SAYS IT ONLY REMOVES THE FIRST INSTANCE OF THE WORD ANYWAY....LEAVING FOR TOMORROW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4fd7f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test5 = remove_stopwords(blogs,'stemmed',extra_words=[],exclude_words=['no','not'])\n",
    "# test5.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3025fa",
   "metadata": {},
   "source": [
    "6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe `news_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34cf0239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>date_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Drop in Meta's market value more than the tota...</td>\n",
       "      <td>Arshiya Chopra</td>\n",
       "      <td>After Facebook parent Meta lost $251 billion i...</td>\n",
       "      <td>04 Feb 2022,Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Facebook's user growth in India slowed due to ...</td>\n",
       "      <td>Sakshita Khosla</td>\n",
       "      <td>Facebook's user growth in India was hit due to...</td>\n",
       "      <td>04 Feb 2022,Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    section                                              title  \\\n",
       "0  business  Drop in Meta's market value more than the tota...   \n",
       "1  business  Facebook's user growth in India slowed due to ...   \n",
       "\n",
       "            author                                            content  \\\n",
       "0   Arshiya Chopra  After Facebook parent Meta lost $251 billion i...   \n",
       "1  Sakshita Khosla  Facebook's user growth in India was hit due to...   \n",
       "\n",
       "       date_published  \n",
       "0  04 Feb 2022,Friday  \n",
       "1  04 Feb 2022,Friday  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = acquire.get_news_articles(cached=True)\n",
    "news_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "237a467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.rename(columns={'content': 'original'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94007d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>original</th>\n",
       "      <th>date_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Drop in Meta's market value more than the tota...</td>\n",
       "      <td>Arshiya Chopra</td>\n",
       "      <td>After Facebook parent Meta lost $251 billion i...</td>\n",
       "      <td>04 Feb 2022,Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    section                                              title  \\\n",
       "0  business  Drop in Meta's market value more than the tota...   \n",
       "\n",
       "           author                                           original  \\\n",
       "0  Arshiya Chopra  After Facebook parent Meta lost $251 billion i...   \n",
       "\n",
       "       date_published  \n",
       "0  04 Feb 2022,Friday  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ccaa9",
   "metadata": {},
   "source": [
    "7. Make another dataframe for the Codeup blog posts. Name the dataframe `codeup_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dc1081d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_published</th>\n",
       "      <th>article_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>Jan 26, 2022</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VET TEC Funding Now Available For Dallas Veterans</td>\n",
       "      <td>Jan 7, 2022</td>\n",
       "      <td>We are so happy to announce that VET TEC benef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title date_published  \\\n",
       "0                  Codeup Start Dates for March 2022   Jan 26, 2022   \n",
       "1  VET TEC Funding Now Available For Dallas Veterans    Jan 7, 2022   \n",
       "\n",
       "                                     article_content  \n",
       "0  As we approach the end of January we wanted to...  \n",
       "1  We are so happy to announce that VET TEC benef...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = acquire.get_blog_articles(cached=True)\n",
    "codeup_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a210500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date_published</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup Start Dates for March 2022</td>\n",
       "      <td>Jan 26, 2022</td>\n",
       "      <td>As we approach the end of January we wanted to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title date_published  \\\n",
       "0  Codeup Start Dates for March 2022   Jan 26, 2022   \n",
       "\n",
       "                                            original  \n",
       "0  As we approach the end of January we wanted to...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df.rename(columns={'article_content': 'original'}, inplace=True)\n",
    "codeup_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860eecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81315ea3",
   "metadata": {},
   "source": [
    "8. For each dataframe, produce the following columns:\n",
    "- `title` to hold the title\n",
    "- `original` to hold the original article/post content\n",
    "- `clean` to hold the normalized and tokenized original with the stopwords removed.\n",
    "- `stemmed` to hold the stemmed version of the cleaned data.\n",
    "- `lemmatized` to hold the lemmatized version of the cleaned data.\n",
    "\n",
    "Ask yourself:\n",
    "\n",
    "If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7a8c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b08ea1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = prepare.prep_article_data(news_df, 'original', extra_words = ['ha'], \\\n",
    "                                    exclude_words = ['no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ac0cd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop in Meta's market value more than the tota...</td>\n",
       "      <td>After Facebook parent Meta lost $251 billion i...</td>\n",
       "      <td>facebook parent meta lost 251 billion market v...</td>\n",
       "      <td>facebook parent meta lost 251 billion market v...</td>\n",
       "      <td>facebook parent meta lost 251 billion market v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook's user growth in India slowed due to ...</td>\n",
       "      <td>Facebook's user growth in India was hit due to...</td>\n",
       "      <td>facebooks user growth india hit due hike prepa...</td>\n",
       "      <td>facebook user growth india wa hit due hike pre...</td>\n",
       "      <td>facebooks user growth india wa hit due hike pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meta drops below Berkshire Hathaway in market ...</td>\n",
       "      <td>Meta Platforms is now worth about $50 billion ...</td>\n",
       "      <td>meta platforms worth 50 billion less berkshire...</td>\n",
       "      <td>meta platform worth 50 billion less berkshir h...</td>\n",
       "      <td>meta platform worth 50 billion le berkshire ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon adds $135 bn in one of the biggest 1-da...</td>\n",
       "      <td>Amazon added more than $135 billion in market ...</td>\n",
       "      <td>amazon added 135 billion market value one bigg...</td>\n",
       "      <td>amazon ad 135 billion market valu one biggest ...</td>\n",
       "      <td>amazon added 135 billion market value one bigg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mukesh Ambani buys ₹13cr Rolls-Royce SUV, one ...</td>\n",
       "      <td>Reliance Industries Chairman Mukesh Ambani has...</td>\n",
       "      <td>reliance industries chairman mukesh ambani bou...</td>\n",
       "      <td>relianc industri chairman mukesh ambani bought...</td>\n",
       "      <td>reliance industry chairman mukesh ambani bough...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Drop in Meta's market value more than the tota...   \n",
       "1  Facebook's user growth in India slowed due to ...   \n",
       "2  Meta drops below Berkshire Hathaway in market ...   \n",
       "3  Amazon adds $135 bn in one of the biggest 1-da...   \n",
       "4  Mukesh Ambani buys ₹13cr Rolls-Royce SUV, one ...   \n",
       "\n",
       "                                            original  \\\n",
       "0  After Facebook parent Meta lost $251 billion i...   \n",
       "1  Facebook's user growth in India was hit due to...   \n",
       "2  Meta Platforms is now worth about $50 billion ...   \n",
       "3  Amazon added more than $135 billion in market ...   \n",
       "4  Reliance Industries Chairman Mukesh Ambani has...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  facebook parent meta lost 251 billion market v...   \n",
       "1  facebooks user growth india hit due hike prepa...   \n",
       "2  meta platforms worth 50 billion less berkshire...   \n",
       "3  amazon added 135 billion market value one bigg...   \n",
       "4  reliance industries chairman mukesh ambani bou...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  facebook parent meta lost 251 billion market v...   \n",
       "1  facebook user growth india wa hit due hike pre...   \n",
       "2  meta platform worth 50 billion less berkshir h...   \n",
       "3  amazon ad 135 billion market valu one biggest ...   \n",
       "4  relianc industri chairman mukesh ambani bought...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  facebook parent meta lost 251 billion market v...  \n",
       "1  facebooks user growth india wa hit due hike pr...  \n",
       "2  meta platform worth 50 billion le berkshire ha...  \n",
       "3  amazon added 135 billion market value one bigg...  \n",
       "4  reliance industry chairman mukesh ambani bough...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad721356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drop in Meta's market value more than the tota...</td>\n",
       "      <td>After Facebook parent Meta lost $251 billion i...</td>\n",
       "      <td>facebook parent meta lost 251 billion market v...</td>\n",
       "      <td>facebook parent meta lost 251 billion market v...</td>\n",
       "      <td>facebook parent meta lost 251 billion market v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook's user growth in India slowed due to ...</td>\n",
       "      <td>Facebook's user growth in India was hit due to...</td>\n",
       "      <td>facebooks user growth india hit due hike prepa...</td>\n",
       "      <td>facebook user growth india wa hit due hike pre...</td>\n",
       "      <td>facebooks user growth india wa hit due hike pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meta drops below Berkshire Hathaway in market ...</td>\n",
       "      <td>Meta Platforms is now worth about $50 billion ...</td>\n",
       "      <td>meta platforms worth 50 billion less berkshire...</td>\n",
       "      <td>meta platform worth 50 billion less berkshir h...</td>\n",
       "      <td>meta platform worth 50 billion le berkshire ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon adds $135 bn in one of the biggest 1-da...</td>\n",
       "      <td>Amazon added more than $135 billion in market ...</td>\n",
       "      <td>amazon added 135 billion market value one bigg...</td>\n",
       "      <td>amazon ad 135 billion market valu one biggest ...</td>\n",
       "      <td>amazon added 135 billion market value one bigg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mukesh Ambani buys ₹13cr Rolls-Royce SUV, one ...</td>\n",
       "      <td>Reliance Industries Chairman Mukesh Ambani has...</td>\n",
       "      <td>reliance industries chairman mukesh ambani bou...</td>\n",
       "      <td>relianc industri chairman mukesh ambani bought...</td>\n",
       "      <td>reliance industry chairman mukesh ambani bough...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Drop in Meta's market value more than the tota...   \n",
       "1  Facebook's user growth in India slowed due to ...   \n",
       "2  Meta drops below Berkshire Hathaway in market ...   \n",
       "3  Amazon adds $135 bn in one of the biggest 1-da...   \n",
       "4  Mukesh Ambani buys ₹13cr Rolls-Royce SUV, one ...   \n",
       "\n",
       "                                            original  \\\n",
       "0  After Facebook parent Meta lost $251 billion i...   \n",
       "1  Facebook's user growth in India was hit due to...   \n",
       "2  Meta Platforms is now worth about $50 billion ...   \n",
       "3  Amazon added more than $135 billion in market ...   \n",
       "4  Reliance Industries Chairman Mukesh Ambani has...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  facebook parent meta lost 251 billion market v...   \n",
       "1  facebooks user growth india hit due hike prepa...   \n",
       "2  meta platforms worth 50 billion less berkshire...   \n",
       "3  amazon added 135 billion market value one bigg...   \n",
       "4  reliance industries chairman mukesh ambani bou...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  facebook parent meta lost 251 billion market v...   \n",
       "1  facebook user growth india wa hit due hike pre...   \n",
       "2  meta platform worth 50 billion less berkshir h...   \n",
       "3  amazon ad 135 billion market valu one biggest ...   \n",
       "4  relianc industri chairman mukesh ambani bought...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  facebook parent meta lost 251 billion market v...  \n",
       "1  facebooks user growth india wa hit due hike pr...  \n",
       "2  meta platform worth 50 billion le berkshire ha...  \n",
       "3  amazon added 135 billion market value one bigg...  \n",
       "4  reliance industry chairman mukesh ambani bough...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = prepare.prep_article_data(news_df, 'original', extra_words = ['ha'], \\\n",
    "                                      exclude_words = ['no'])\n",
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90107f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title</td>\n",
       "      <td>Content</td>\n",
       "      <td>Clean_content</td>\n",
       "      <td>Cleaned, stemmed</td>\n",
       "      <td>Cleaned, lemmatized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>etc</td>\n",
       "      <td>etc</td>\n",
       "      <td>etc</td>\n",
       "      <td>etc</td>\n",
       "      <td>etc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title original          clean           stemmed           lemmatized\n",
       "0  Title  Content  Clean_content  Cleaned, stemmed  Cleaned, lemmatized\n",
       "1    etc      etc            etc               etc                  etc"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = pd.DataFrame(\n",
    "    {\n",
    "        'title':['Title','etc'],\n",
    "        'original':['Content','etc'],\n",
    "        'clean':['Clean_content','etc'],\n",
    "        'stemmed':['Cleaned, stemmed','etc'],\n",
    "        'lemmatized':['Cleaned, lemmatized','etc']\n",
    "    }\n",
    ")\n",
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a33528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78658bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
